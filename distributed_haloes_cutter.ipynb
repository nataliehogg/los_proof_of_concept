{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Distributed haloes cutter\n",
    "<b>Author</b>: Natalie B. Hogg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `lenstronomy` to create an image produced by the so-called \"distributed haloes\" model, where we have a main lens modelled by an EPL profile, with a large number of NFW haloes along the line-of-sight, both in front of and behind the main lens. We draw the positions of the haloes from a plectrum-shaped volume whose radius is dependent on the number density of haloes and the comoving distances from observer to halo and observer to source. We obtain the number density of the haloes and their masses from a halo mass function computed using `colossus`. We use the multi-plane lensing functionality of `lenstronomy` to place the haloes along the line-of-sight.\n",
    "\n",
    "We create a mock image that would be observed in this situation, and attempt to fit it with a model which includes an EPL main lens plus line-of-sight shear. We aim to show that the MCMC can correctly recover the predicted LOS shears. We find that a number of haloes break the tidal approximation and induce a flexion-like residual in the reconstructed image. With these beyond-tidal haloes removed from the population, the LOS shears are recovered perfectly.\n",
    "\n",
    "**This notebook loads the saved haloes and removes problematic ones, recomputes the shears and saves the surviving sample to a new file**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contents <a name=\"contents\"></a>\n",
    "1. [Set up](#setup)\n",
    "2. [Load data](#load)\n",
    "3. [Compute the shears](#predict_shears)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up <a name=\"setup\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random as r\n",
    "\n",
    "# plotting\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import rc, rcParams, rcParamsDefault\n",
    "from mpl_toolkits import mplot3d\n",
    "\n",
    "# cosmology\n",
    "from colossus.cosmology import cosmology as colcos\n",
    "from colossus.lss import mass_function\n",
    "from colossus.halo import concentration\n",
    "from astropy.table import Table\n",
    "from astropy.cosmology import FlatLambdaCDM, z_at_value\n",
    "from astropy import constants as const\n",
    "from astropy import units as u\n",
    "\n",
    "# monitoring\n",
    "from tqdm.notebook import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "outpath  = r'/home/natalie/Documents/Projects/los_effects/figures/distributed_haloes/simple/' \n",
    "\n",
    "job_name = 'million'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import `lenstronomy` packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lenstronomy.LensModel.lens_model import LensModel\n",
    "from lenstronomy.Cosmo.lens_cosmo import LensCosmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_palette(colour):\n",
    "    # function for displaying colour palettes\n",
    "    sns.set_style('whitegrid')\n",
    "    hex2rgb = []\n",
    "    for k in colour:\n",
    "        h = k.lstrip('#')\n",
    "        hex2rgb.append(tuple(int(h[i:i + 2], 16) / 255.0 for i in (0, 2, 4)))\n",
    "    return sns.palplot(hex2rgb)\n",
    "\n",
    "def ellipticity(phi, q):\n",
    "    # transforms orientation angle phi and aspect ratio q into complex ellipticity modulii e1, e2\n",
    "    e1 = (1 - q)/(1 + q)*np.cos(2*phi)\n",
    "    e2 = (1 - q)/(1 + q)*np.sin(2*phi)\n",
    "    return e1, e2\n",
    "\n",
    "def colorbar(mappable):\n",
    "    # makes handling colour bars in matplotlib much easier\n",
    "    # thanks to Joseph Long! https://joseph-long.com/writing/colorbars/\n",
    "    last_axes = plt.gca()\n",
    "    ax = mappable.axes\n",
    "    fig = ax.figure\n",
    "    divider = make_axes_locatable(ax)\n",
    "    cax = divider.append_axes('right', size = '5%', pad = 0.05)\n",
    "    cbar = fig.colorbar(mappable, cax = cax)\n",
    "    plt.sca(last_axes)\n",
    "    return cbar\n",
    "\n",
    "def distance_conversion(distance, conversion_type):\n",
    "    # converts a distance *in Mpc* to Gpc, kpc, pc or m\n",
    "    # careful! it doesn't sanity check your input\n",
    "    if conversion_type == 'to Gpc':\n",
    "        new_distance = distance/(10**3)\n",
    "    elif conversion_type == 'to kpc':\n",
    "        new_distance = distance*(10**3)\n",
    "    elif conversion_type == 'to pc':\n",
    "        new_distance = distance*(10**6)\n",
    "    elif conversion_type == 'to m':\n",
    "        new_distance = distance*(3.086*10**22)\n",
    "    else:\n",
    "        print('Unknown conversion type')\n",
    "    return new_distance\n",
    "\n",
    "def angle_conversion(angle, conversion_type):\n",
    "    # converts an angle in arcsec to rad or rad to arcsec\n",
    "    # careful! it doesn't sanity check your input\n",
    "    conversion_factor = np.pi/(180*3600)\n",
    "    if conversion_type == 'to arcsecs':\n",
    "        new_angle = angle/conversion_factor\n",
    "    elif conversion_type == 'to radians':\n",
    "        new_angle = angle*conversion_factor\n",
    "    else:\n",
    "        print('Unknown conversion type')\n",
    "    return new_angle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global plotting and display settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAALUAAABECAYAAADHnXQVAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAABYElEQVR4nO3YMWpVQQCG0YmRPLsI7kBIK3cNLsctCIKVfZbgDlyDTYoUr3ARFkGxkieacQHRRwqvl3ycU840f/EVw5zMOeeAkEdbD4B/TdTkiJocUZMjanIeH7u8ur4en392P0ee3o5x8/3X1jNW8+x0jJsvh61nrObi+flYluXO+dGo5xzj8uuPtTZt7tXZ6Xj78dvWM1bz5sWT8frdp61nrObD+5d/PPf8IEfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyRE2OqMkRNTmiJkfU5IiaHFGTI2pyTuac82+X+/1+7Ha7/7kH7u1wOIxlWe6cH40aHiLPD3JETY6oyRE1OaIm5zfe8iq+TetWvgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 216x72 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# contour plot colours\n",
    "# thanks to colorbrewer for these palettes! https://colorbrewer2.org\n",
    "green        = ['#a6dba0','#5aae61','#1b7837']\n",
    "purple       = ['#c2a5cf', '#9970ab', '#762a83']\n",
    "analogous    = ['#a0c3db', '#dbb7a0']\n",
    "warm         = ['#fdcc8a', '#fc8d59', '#d7301f']\n",
    "cool         = ['#41b6c4', '#2c7fb8', '#253494']\n",
    "\n",
    "# have a look at a palette for example\n",
    "show_palette(cool)\n",
    "\n",
    "# set the seaborn style\n",
    "sns.set_style('ticks')\n",
    "\n",
    "# use TeX for plot labels\n",
    "rc('text', usetex=True)\n",
    "rc('font', family='serif')\n",
    "matplotlib.rcParams.update({'font.size': 18})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Universe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Hubble parameter being used is 67.4 km/s/Mpc.\n",
      "The redshifts of the observer, lens and the source are z = 0.0, z = 0.5 and z = 1.5 respectively.\n",
      "The distances between observer and lens, observer and source and lens and source are 1300.92 Mpc, 1792.84 Mpc and 1012.28 Mpc respectively.\n"
     ]
    }
   ],
   "source": [
    "cosmology = {'id': 'planck18', 'H0': 67.4, 'Om': 0.315}\n",
    "\n",
    "colcos.setCosmology(cosmology['id'])\n",
    "\n",
    "cosmo = FlatLambdaCDM(H0 = cosmology['H0'], Om0 = cosmology['Om']) \n",
    "\n",
    "G_Newton   = const.G.value # 6.67*10**-11 [m^3 / kg s^2]\n",
    "clight     = const.c.value # 299792458 [m / s]\n",
    "clight_kms = clight/1000   # 299792.458 [km / s]\n",
    "solar_mass = const.M_sun.value # 1.988*10**30 [kg]\n",
    "parsec     = const.pc.value # 3.08567758*10**16 [m]\n",
    "\n",
    "def dC(redshift):\n",
    "    \"\"\"\n",
    "    Returns the comoving distance at a given redshift in Mpc.\n",
    "    \"\"\"\n",
    "    distance = cosmo.comoving_distance(redshift).value\n",
    "    return distance\n",
    "\n",
    "def Hubble(redshift):\n",
    "    \"\"\"\n",
    "    Returns H(z) for a given redshift in km/s/Mpc.\n",
    "    \"\"\"\n",
    "    Hofz = cosmo.H(redshift).value\n",
    "    return Hofz\n",
    "\n",
    "def dA(z1, z2):\n",
    "    \"\"\"\n",
    "    Returns angular diameter distance between two redshifts in Mpc.\n",
    "    \"\"\"\n",
    "    distance = cosmo.angular_diameter_distance_z1z2(z1, z2).value\n",
    "    return distance\n",
    "\n",
    "def redshift_converter(object_distance, units):\n",
    "    object_redshift = z_at_value(cosmo.comoving_distance, object_distance*units, zmin = -0.0001, zmax=5.)\n",
    "    return object_redshift\n",
    "\n",
    "z_observer = 0.0\n",
    "z_lens     = 0.5 \n",
    "z_source   = 1.5\n",
    "\n",
    "d_observer = 0.0\n",
    "d_od       = dA(z_observer, z_lens)\n",
    "d_os       = dA(z_observer, z_source)\n",
    "d_ds       = dA(z_lens, z_source)\n",
    "\n",
    "dc_source = dC(z_source)\n",
    "\n",
    "print('\\nThe Hubble parameter being used is {} km/s/Mpc.'.format(cosmo.h*100))\n",
    "print('The redshifts of the observer, lens and the source are z = {}, z = {:.2} and z = {} respectively.'.format(z_observer, z_lens, z_source))\n",
    "print('The distances between observer and lens, observer and source and lens and source are {:.2f} Mpc, {:.2f} Mpc and {:.2f} Mpc respectively.'.format(d_od, d_os, d_ds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the halo data <a name=\"load\"> </a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "haloes_fits = Table.read(outpath + 'total_haloes_dataframe_' + job_name + '.fits')\n",
    "\n",
    "haloes_dataframe = haloes_fits.to_pandas()\n",
    "\n",
    "halo_number = len(haloes_dataframe)\n",
    "\n",
    "halo_redshift_list = haloes_dataframe['z'].to_list()\n",
    "\n",
    "kwargs_nfw = haloes_dataframe[['Rs', 'alpha_Rs', 'center_x', 'center_y']].to_dict('records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "maximum_convergence = 0.5\n",
    "maximum_Del = 0.1\n",
    "\n",
    "# split the halo dataframe into good and bad\n",
    "discarded_haloes_dataframe = haloes_dataframe.loc[(haloes_dataframe['kappa'] > maximum_convergence) | (haloes_dataframe['Del'] > maximum_Del)]\n",
    "surviving_haloes_dataframe = haloes_dataframe.loc[(haloes_dataframe['kappa'] <= maximum_convergence) & (haloes_dataframe['Del'] <= maximum_Del)]\n",
    "\n",
    "discarded_halo_number = len(discarded_haloes_dataframe)\n",
    "surviving_halo_number = len(surviving_haloes_dataframe)\n",
    "\n",
    "# check the split is correct\n",
    "assert discarded_halo_number + surviving_halo_number == halo_number\n",
    "\n",
    "# get rid of the kappa os and Del\n",
    "discarded_haloes_dataframe.drop(['kappa', 'Del'], axis = 1, inplace = True)\n",
    "surviving_haloes_dataframe.drop(['kappa', 'Del'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict the LOS terms: surviving haloes <a name=\"predict_shears\"></a>\n",
    "\n",
    "[Back to contents](#contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a dataframe to save them\n",
    "surviving_shears_dataframe = pd.DataFrame(columns = ['gamma1_os', 'gamma2_os', 'kappa_os',\n",
    "                                                     'gamma1_od', 'gamma2_od', 'kappa_od',\n",
    "                                                     'gamma1_ds', 'gamma2_ds', 'kappa_ds',\n",
    "                                                     'gamma1_los', 'gamma2_los', 'kappa_los'])\n",
    "\n",
    "# dummy row so we can write scalars directly to the df\n",
    "surviving_shears_dataframe = surviving_shears_dataframe.append(pd.Series('dummy'), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the os component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting os convergence and shear\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc5e24aff6474b368034f2be15aef8ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10474 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get the kwargs of the surviving haloes\n",
    "surviving_halo_redshift_list = surviving_haloes_dataframe['z'].to_list()\n",
    "\n",
    "# get the parameters needed for the lenstronomy kwargs and convert to list of dicts\n",
    "kwargs_surviving_nfw = surviving_haloes_dataframe[['Rs', 'alpha_Rs', \n",
    "                                                   'center_x', 'center_y']].to_dict('records')\n",
    "\n",
    "os_lens_model = LensModel(lens_model_list = ['NFW'], z_source = z_source)\n",
    "\n",
    "gamma1_os = []\n",
    "gamma2_os = []\n",
    "kappa_os  = []\n",
    "alpha1_os = []\n",
    "alpha2_os = []\n",
    "\n",
    "\n",
    "print('\\nGetting os convergence and shear')\n",
    "for i in tqdm(range(len(surviving_halo_redshift_list))):\n",
    "    gamma_os = os_lens_model.gamma(x = 0.0, y = 0.0, kwargs = [kwargs_surviving_nfw[i]])\n",
    "    gamma1_os.append(float(gamma_os[0]))\n",
    "    gamma2_os.append(float(gamma_os[1]))\n",
    "    kappa_os_calc = os_lens_model.kappa(x = 0.0, y = 0.0, kwargs = [kwargs_surviving_nfw[i]])\n",
    "    kappa_os.append(float(kappa_os_calc))\n",
    "    alpha_os = os_lens_model.alpha(x = 0.0, y = 0.0, kwargs = [kwargs_surviving_nfw[i]])\n",
    "    alpha1_os.append(float(alpha_os[0]))\n",
    "    alpha2_os.append(float(alpha_os[1]))\n",
    "    \n",
    "expected_gamma_os_1 = sum(gamma1_os)\n",
    "expected_gamma_os_2 = sum(gamma2_os)\n",
    "expected_kappa_os   = sum(kappa_os)\n",
    "alpha1_os = sum(alpha1_os)\n",
    "alpha2_os = sum(alpha2_os)\n",
    "\n",
    "surviving_shears_dataframe['gamma1_os'] = expected_gamma_os_1\n",
    "surviving_shears_dataframe['gamma2_os'] = expected_gamma_os_2\n",
    "surviving_shears_dataframe['kappa_os'] = expected_kappa_os\n",
    "surviving_shears_dataframe['alpha1_os'] = alpha1_os\n",
    "surviving_shears_dataframe['alpha2_os'] = alpha2_os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the od component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting od convergence and shear\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b439698967c43a093d3f9df188ee677",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3839 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "foreground_haloes_dataframe = surviving_haloes_dataframe[surviving_haloes_dataframe['z'].between(z_observer, z_lens)]\n",
    "\n",
    "foreground_halo_redshift_list = foreground_haloes_dataframe['z'].to_list()\n",
    "\n",
    "kwargs_foreground_nfw = foreground_haloes_dataframe[['Rs', 'alpha_Rs', \n",
    "                                                     'center_x', 'center_y']].to_dict('records')\n",
    "\n",
    "def foreground_distance(z_halo):\n",
    "    d_hd = dA(z_halo, z_lens)\n",
    "    d_hs = dA(z_halo, z_source)\n",
    "    distance = (d_os*d_hd)/(d_od*d_hs)\n",
    "    return distance\n",
    "\n",
    "od_lens_model = LensModel(lens_model_list = ['NFW'], z_source = z_source)\n",
    "\n",
    "gamma1_od = []\n",
    "gamma2_od = []\n",
    "kappa_od  = []\n",
    "alpha1_od = []\n",
    "alpha2_od = []\n",
    "\n",
    "print('\\nGetting od convergence and shear')\n",
    "for i in tqdm(range(len(foreground_halo_redshift_list))):\n",
    "    gamma_od = od_lens_model.gamma(x = 0.0, y = 0.0, kwargs = [kwargs_foreground_nfw[i]])\n",
    "    kappa_od_calc = od_lens_model.kappa(x = 0.0, y = 0.0, kwargs = [kwargs_foreground_nfw[i]])\n",
    "    gamma1_od.append(float(gamma_od[0]))\n",
    "    gamma2_od.append(float(gamma_od[1]))\n",
    "    kappa_od.append(float(kappa_od_calc))    \n",
    "    alpha_od = od_lens_model.alpha(x = 0.0, y = 0.0, kwargs = [kwargs_foreground_nfw[i]])\n",
    "    alpha1_od.append(float(alpha_od[0]))\n",
    "    alpha2_od.append(float(alpha_od[1]))\n",
    "        \n",
    "foreground_distance_combination = [foreground_distance(i) for i in foreground_halo_redshift_list]\n",
    "    \n",
    "expected_gamma_od_1 = sum(np.multiply(gamma1_od, foreground_distance_combination))\n",
    "expected_gamma_od_2 = sum(np.multiply(gamma2_od, foreground_distance_combination))\n",
    "expected_kappa_od = sum(np.multiply(kappa_od, foreground_distance_combination))\n",
    "alpha1_od = sum(np.multiply(alpha1_od, foreground_distance_combination))\n",
    "alpha2_od = sum(np.multiply(alpha2_od, foreground_distance_combination))\n",
    "\n",
    "surviving_shears_dataframe['gamma1_od'] = expected_gamma_od_1\n",
    "surviving_shears_dataframe['gamma2_od'] = expected_gamma_od_2\n",
    "surviving_shears_dataframe['kappa_od'] = expected_kappa_od\n",
    "\n",
    "surviving_shears_dataframe['alpha1_od'] = alpha1_od\n",
    "surviving_shears_dataframe['alpha2_od'] = alpha2_od"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the ds component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Getting ds convergence and shear\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24b356d803834a17b00cc44736a976eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6635 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "background_haloes_dataframe = surviving_haloes_dataframe[surviving_haloes_dataframe['z'].between(z_lens, z_source)]\n",
    "\n",
    "background_halo_redshift_list = background_haloes_dataframe['z'].to_list()\n",
    "\n",
    "kwargs_background_nfw = background_haloes_dataframe[['Rs', 'alpha_Rs', \n",
    "                                                     'center_x', 'center_y']].to_dict('records')\n",
    "\n",
    "def background_distance(z_halo):\n",
    "    d_db = dA(z_lens, z_halo)\n",
    "    d_ob = dA(z_observer, z_halo)\n",
    "    distance = (d_os*d_db)/(d_ob*d_ds)\n",
    "    return distance\n",
    "\n",
    "\n",
    "ds_lens_model = LensModel(lens_model_list = ['NFW'], z_source = z_source)\n",
    "\n",
    "gamma1_ds = []\n",
    "gamma2_ds = []\n",
    "kappa_ds  = []\n",
    "\n",
    "print('\\nGetting ds convergence and shear')\n",
    "for i in tqdm(range(len(background_halo_redshift_list))):\n",
    "    gamma_ds = ds_lens_model.gamma(x = 0.0, y = 0.0, kwargs = [kwargs_background_nfw[i]])\n",
    "    gamma1_ds.append(float(gamma_ds[0]))\n",
    "    gamma2_ds.append(float(gamma_ds[1]))\n",
    "    kappa_ds_calc = ds_lens_model.kappa(x = 0.0, y = 0.0, kwargs = [kwargs_background_nfw[i]])\n",
    "    kappa_ds.append(float(kappa_ds_calc))\n",
    "    \n",
    "background_distance_combination = [background_distance(i) for i in background_halo_redshift_list]\n",
    "    \n",
    "expected_gamma_ds_1 = sum(np.multiply(gamma1_ds, background_distance_combination))\n",
    "expected_gamma_ds_2 = sum(np.multiply(gamma2_ds, background_distance_combination))\n",
    "expected_kappa_ds = sum(np.multiply(kappa_ds, background_distance_combination))\n",
    "\n",
    "surviving_shears_dataframe['gamma1_ds'] = expected_gamma_ds_1\n",
    "surviving_shears_dataframe['gamma2_ds'] = expected_gamma_ds_2\n",
    "surviving_shears_dataframe['kappa_ds'] = expected_kappa_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the LOS component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_gamma_LOS_1 = expected_gamma_os_1 + expected_gamma_od_1 - expected_gamma_ds_1\n",
    "expected_gamma_LOS_2 = expected_gamma_os_2 + expected_gamma_od_2 - expected_gamma_ds_2\n",
    "expected_kappa_LOS   = expected_kappa_os + expected_kappa_od - expected_kappa_ds\n",
    "\n",
    "surviving_shears_dataframe['gamma1_los'] = expected_gamma_LOS_1\n",
    "surviving_shears_dataframe['gamma2_los'] = expected_gamma_LOS_2\n",
    "surviving_shears_dataframe['kappa_los'] = expected_kappa_LOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted shear components with problematic haloes removed are:\n",
      "gamma_os  = (-9.991e-03, 3.409e-02)\n",
      "gamma_od  = (1.307e-03, 8.465e-03)\n",
      "gamma_ds  = (-7.143e-03, 1.179e-02)\n",
      "gamma_LOS = (-1.541e-03, 3.076e-02)\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe predicted shear components with problematic haloes removed are:')\n",
    "print('gamma_os  = ({:.3e}, {:.3e})'.format(expected_gamma_os_1, expected_gamma_os_2))\n",
    "print('gamma_od  = ({:.3e}, {:.3e})'.format(expected_gamma_od_1, expected_gamma_od_2))\n",
    "print('gamma_ds  = ({:.3e}, {:.3e})'.format(expected_gamma_ds_1, expected_gamma_ds_2))\n",
    "print('gamma_LOS = ({:.3e}, {:.3e})'.format(expected_gamma_LOS_1, expected_gamma_LOS_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The predicted convergence components are:\n",
      "kappa_os  = 3.049e-01.\n",
      "kappa_od  = 2.770e-02.\n",
      "kappa_ds  = 1.617e-01.\n",
      "kappa_LOS = 1.709e-01.\n"
     ]
    }
   ],
   "source": [
    "print('\\nThe predicted convergence components are:')\n",
    "print('kappa_os  = {:.3e}.'.format(expected_kappa_os))\n",
    "print('kappa_od  = {:.3e}.'.format(expected_kappa_od))\n",
    "print('kappa_ds  = {:.3e}.'.format(expected_kappa_ds))\n",
    "print('kappa_LOS = {:.3e}.'.format(expected_kappa_LOS))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the final dataframes to file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write haloes to fits\n",
    "surviving_haloes_fits = Table.from_pandas(surviving_haloes_dataframe)\n",
    "surviving_haloes_fits.write(outpath + 'surviving_haloes_dataframe_' + job_name + '.fits', overwrite = True)\n",
    "\n",
    "# write shears to csv\n",
    "surviving_shears_dataframe.to_csv(outpath + 'surviving_shears_dataframe_' + job_name + '.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Back to contents](#contents)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
